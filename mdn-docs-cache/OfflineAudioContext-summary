The <code>OfflineAudioContext</code> interface is an <a href="/en-US/docs/Web/API/AudioContext" title="The AudioContext interface represents an audio-processing graph built from audio modules linked together, each represented by an AudioNode."><code>AudioContext</code></a> interface representing an audio-processing graph built from linked together <a href="/en-US/docs/Web/API/AudioNode" title="The AudioNode interface is a generic interface for representing an audio processing module. Examples include:"><code>AudioNode</code></a>s. In contrast with a standard <a href="/en-US/docs/Web/API/AudioContext" title="The AudioContext interface represents an audio-processing graph built from audio modules linked together, each represented by an AudioNode."><code>AudioContext</code></a>, an <code>OfflineAudioContext</code> doesn't render the audio to the device hardware; instead, it generates it, as fast as it can, and outputs the result to an <a href="/en-US/docs/Web/API/AudioBuffer" title="Objects of these types are designed to hold small audio snippets, typically less than 45 s. For longer sounds, objects implementing the MediaElementAudioSourceNode are more suitable. The buffer contains data in the following format:  non-interleaved IEEE754 32-bit linear PCM with a nominal range between -1 and +1, that is, 32bits floating point buffer, with each samples between -1.0 and 1.0. If the AudioBuffer has multiple channels, they are stored in separate buffer."><code>AudioBuffer</code></a>.